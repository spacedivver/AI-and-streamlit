import streamlit as st
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_openai import ChatOpenAI


OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]

st.title("ğŸ“•ğŸ“ğŸ” PDF ê²€ìƒ‰ ì„œë¹„ìŠ¤")

# 1. Load
# PDF ë¬¸ì„œë“¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
def get_pdf_texts(pdf_docs):
    texts = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            texts += page.extract_text()

    return texts

# 2. Chunk
# í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í• 
def get_text_chunks(raw_text):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # ì²­í¬ì˜ í¬ê¸°
        chunk_overlap=50  # ì²­í¬ ì‚¬ì´ì˜ ì¤‘ë³µ ì •ë„
    )

    chunks = text_splitter.split_text(raw_text)
    return chunks

# 3. Embed + Store
def get_vectorstore(text_chunks):
    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    vectorstore = FAISS.from_texts(text_chunks, embeddings)
    return vectorstore

# =========================================================================================
# torch ì‚¬ìš© ë²„ì „(ìš©ëŸ‰ í¬ê³  ì˜¤ë¥˜ ë§ìŒ)

# from sentence_transformers import SentenceTransformer
# from langchain_community.vectorstores import FAISS
# import torch

# def get_vectorstore(text_chunks):
#     # Use a free, open-source embedding model from Hugging Face
#     model = SentenceTransformer('all-MiniLM-L6-v2')
#
#     # Create embeddings
#     embeddings = model.encode(text_chunks)
#
#     # Create FAISS vector store
#     vectorstore = FAISS.from_embeddings(
#         text_embedding_pairs=list(zip(text_chunks, embeddings)),
#         embedding=None  # We'll pass None since we've already created embeddings
#     )
#
#     return vectorstore

# =========================================================================================

# 4. Chain
def get_conversation_chain(vectorstore):
    # ConversationBufferWindowMemoryì— ì´ì „ ëŒ€í™” ì €ì¥
    llm = ChatOpenAI(
        model_name="gpt-3.5-turbo",  # ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        temperature=0.7,  # ìƒì„±ëœ ë‹µë³€ì˜ ì¼ê´€ì„±ì„ ë†’ì´ê¸° ìœ„í•´ temperature=0ìœ¼ë¡œ ì„¤ì •
        openai_api_key=OPENAI_API_KEY  # OpenAI API í‚¤ ì…ë ¥
    )

    # RAG ì‹œìŠ¤í…œ (RetrievalQA ì²´ì¸) êµ¬ì¶•
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,  # ì–¸ì–´ ëª¨ë¸
        chain_type="stuff",  # ê²€ìƒ‰ëœ ëª¨ë“  ë¬¸ì„œë¥¼ í•©ì³ ì „ë‹¬ ("stuff" ë°©ì‹)
        retriever=vectorstore.as_retriever(),  # ë²¡í„° ìŠ¤í† ì–´ ë¦¬íŠ¸ë¦¬ë²„
        return_source_documents=False,  # ë‹µë³€ì— ì‚¬ìš©ëœ ë¬¸ì„œ ì¶œì²˜ ë°˜í™˜
    )
    return qa_chain


user_uploads = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”~ ğŸ“‚", accept_multiple_files=True)
if user_uploads:
    if st.button("PDF ì—…ë¡œë“œ ğŸ¥³"):
        with st.spinner("PDF ì²˜ë¦¬ ì¤‘ì´ì—ìš”~ ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”! â³"):
            # 1. PDF ë¬¸ì„œë“¤ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (Load)
            raw_text = get_pdf_texts(user_uploads)
            # 2. í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  (Chunk)
            chunks = get_text_chunks(raw_text)
            # 3. ë²¡í„° ì €ì¥ì†Œ ë§Œë“¤ê¸° (Embed+Store)
            vectorstore = get_vectorstore(chunks)
            # 4. ëŒ€í™” ì²´ì¸ ë§Œë“¤ê¸° (Chain)
            st.session_state.conversation = get_conversation_chain(vectorstore)

            st.success("PDF ì—…ë¡œë“œ ì™„ë£Œ! ëŒ€í™” ì‹œì‘í•´ ë³´ì„¸ìš”~ ğŸ˜Š")
            ready = True


if user_query := st.chat_input("ê¶ê¸ˆí•œ ê±¸ ì…ë ¥í•´ ì£¼ì„¸ìš”! ğŸ¤"):
    if 'conversation' in st.session_state:
        with st.spinner("ë‹µë³€ ì¤€ë¹„ ì¤‘ì´ì—ìš”~ ğŸ§"):
            result = st.session_state.conversation.invoke({"query": user_query})
            response = result['result']
    else:
        response = "PDFë¥¼ ë¨¼ì € ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”! ğŸ¥º"

    with st.chat_message("assistant"):
        st.write(response)